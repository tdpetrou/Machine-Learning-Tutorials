{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Massive Machine Learning Pipelines - Part 2\n",
    "We will move on to building the massive machine learning pipeline. The overall architecture will look similar to the mini-pipeline from above with the major difference being the number of distinct column groups. Each of the column groupings we create will have its own pipeline.\n",
    "\n",
    "## Create column groupings\n",
    "For this massive pipeline, we will use all of the columns. Typically, it's a good idea to do exploratory data analysis first to manually inspect the columns and possibly select a subset to model on. We will forgo this step and go straight into pipeline construction. Further along in the tutorial we will do some data inspection and feature engineering.\n",
    "\n",
    "Below, we separate the data into five separate column groupings. The data type of each column is either numeric or string. Both numeric and string columns can be categorical, but only numeric data can be continuous. Categorical data is further subdivided into nominal (no natural ordering) or ordinal (has a natural ordering - basement quality for example). The data dictionary was used to help classify each column correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_nomial = ['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', \n",
    "              'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle',\n",
    "              'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'Foundation',\n",
    "              'Heating', 'CentralAir', 'Electrical', 'GarageType', 'GarageFinish', 'PavedDrive',\n",
    "              'MiscFeature', 'SaleType', 'SaleCondition']\n",
    "str_ordinal = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1',\n",
    "               'BsmtFinType2', 'HeatingQC', 'KitchenQual', 'Functional', 'GarageQual', 'GarageCond',\n",
    "               'PoolQC', 'Fence', 'FireplaceQu']\n",
    "\n",
    "numeric_nominal = ['MSSubClass', 'MoSold', 'YrSold', 'YearBuilt', 'YearRemodAdd', 'GarageYrBlt']\n",
    "numeric_ordinal = ['OverallQual', 'OverallCond', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n",
    "                   'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', ]\n",
    "numeric_cont = ['LotFrontage', 'LotArea', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', \n",
    "                'TotalBsmtSF','1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'GarageArea', \n",
    "                'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea',\n",
    "                'MiscVal']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nominal vs Ordinal\n",
    "Most of the time it is easy to determine whether a categorical column is nominal or ordinal. The neighborhood column, for instance has no natural ordering and would therefore be classified as nominal. \n",
    "\n",
    "But with a column like LotShape, it isn't so clear. The values are Reg (Regular), IR1 (Slightly Irregular), IR2 (Moderately Irregular), and IR3 (Irregular). The values appear to have an order with Reg being the 'best' and IR3 the 'worst'. But, without being an expert in this field, it's probably safer to assume less and treat it as a nominal.\n",
    "\n",
    "### One-Hot encoding all categorical columns\n",
    "While scikit-learn does provide an `OrdinalEncoder` to encode ordinal features, we will choose opt to one-hot encode them instead. This is done for a couple reasons. First, ordinal encoding places a stricter assumption on the data, that each category is worth precisely one more than the prior one. Second, we would need to provide an ordered list of categories for each column and that would be quite tedious. So, partly out of laziness, we will one-hot encode all categorical columns regardless if they are nominal or ordinal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create pipeline steps for each column group\n",
    "\n",
    "We will now create a pipeline for each subset of columns. We will fill missing values with the most frequent for all of the categorical columns and with the median for the continuous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_nominal_steps = [\n",
    "    ('si', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "]\n",
    "str_orinal_steps = [\n",
    "    ('si', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "]\n",
    "numeric_nominal_steps = [\n",
    "    ('si', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "]\n",
    "numeric_ordinal_steps = [\n",
    "    ('si', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "]\n",
    "numeric_cont_steps = [\n",
    "    ('si', SimpleImputer(strategy='median')),\n",
    "    ('ss', StandardScaler())\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create pipeline for each column group\n",
    "We instantiate each pipeline with the steps (list of two-item tuples) from above. Notice, that all pipelines are identical except for the continuos one. We could have used just two pipelines to transform the data like we did in our first attempt. In upcoming examples, we will see different sets of transformations applied to each pipeline. Regardless, it is still useful to see how different columns many be categorized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_nominal_pipe = Pipeline(str_nominal_steps)\n",
    "str_ordinal_pipe = Pipeline(str_orinal_steps)\n",
    "numeric_nominal_pipe = Pipeline(numeric_nominal_steps)\n",
    "numeric_ordinal_pipe = Pipeline(numeric_ordinal_steps)\n",
    "numeric_cont_pipe = Pipeline(numeric_cont_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ColumnTransformer\n",
    "We instantiate our `ColumnTransformer` with a list of three-item tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers = [\n",
    "    ('str_nominal_pipe', str_nominal_pipe, str_nomial),\n",
    "    ('str_ordinal_pipe', str_ordinal_pipe, str_ordinal),\n",
    "    ('numeric_nominal_pipe', numeric_nominal_pipe, numeric_nominal),\n",
    "    ('numeric_ordinal_pipe', numeric_ordinal_pipe, numeric_ordinal),\n",
    "    ('numeric_cont_pipe', numeric_cont_pipe, numeric_cont)\n",
    "]\n",
    "ct = ColumnTransformer(transformers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create one last pipeline to add machine learning\n",
    "A final pipeline is created to connect the transformed data to the Ridge regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_steps = [\n",
    "    ('ct', ct),\n",
    "    ('ridge', Ridge())\n",
    "]\n",
    "final_pipe2 = Pipeline(final_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit and predict\n",
    "We can now pass our data into the final pipeline to transform and ultimately train our ridge regression model. We follow this up by predicting the sale price for the test set and saving a new submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pipe2.fit(housing, y)\n",
    "y_pred = final_pipe2.predict(housing_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automate submission to kaggle\n",
    "We can define a function to create the csv, submit the prediction, and return the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_kaggle(model, X_test, file, message):\n",
    "    y_pred = model.predict(X_test)\n",
    "    sub = pd.DataFrame({'Id': X_test['Id'], 'SalePrice': y_pred})\n",
    "    sub.to_csv(file, index=False)\n",
    "    kaggle.api.competition_submit(file, message, competition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'data/submissions/20190710/sub02.csv'\n",
    "message = '''\n",
    "One hot encoded all categorical columns and standardized all continuous\n",
    "columns. Modeled with ridge regression with alpha=1\n",
    "'''\n",
    "# submit_kaggle(final_pipe2, housing, file, message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
